{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UQR2216 Assignment 1\n",
    "### Tian Mengxi (e0555841)\n",
    "An Ordinary Least Squares Multiple Regression model was built by using 9 X-variables to predict the dependent Y-variable ‘room receipt’, after which the RMSE, R^2 and MAE were used as metrics to evaluate the quality of the model’s prediction. \n",
    "\n",
    "The following were taken into consideration in this model:\n",
    "- Categorical variables\n",
    "- Collinearity\n",
    "- Transformations\n",
    "- Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 580 rows.\n",
      "\n",
      "   year  month  days    type  occupancy_rate   room_rate  room_receipt\n",
      "0  2020      1    31  Luxury       83.478003  506.427381    422.755465\n",
      "1  2019     12    31  Luxury       86.472915  493.608149    426.837353\n",
      "2  2019     11    30  Luxury       89.676464  452.747203    406.007682\n",
      "3  2019     10    31  Luxury       87.985274  457.485963    402.520279\n",
      "4  2019      9    30  Luxury       88.450824  489.061425    432.578859\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "df = pd.read_excel('Singapore_Hotel.xlsx')\n",
    "df.columns = df.columns.str.replace(' ','_').str.lower()\n",
    "print('Dataset has', len(df), 'rows.\\n')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up Data\n",
    "1. Drop rows with missing values\n",
    "2. Drop rows with invalid entries. For the numeric columns 'year', 'month', 'days', 'occupancy_rate', 'room_rate' and 'room_receipt', these are rows where the values are negative. \n",
    "3. Display the unique values in 'year', 'month', 'days' and 'type' to ensure that all values are valid, before turn these columsn into categorical variables later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with any missing values\n",
    "df.dropna(how='any', inplace=True)\n",
    "\n",
    "#delete rows with invalid entries\n",
    "df = df[(df.days>0) & (df.occupancy_rate>0) & (df.room_rate>0) & (df.room_receipt>0) &\n",
    "        (df.year>0) & (df.month>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entries in variable 'year': [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "\n",
      "Unique entries in variable 'month': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "\n",
      "Unique entries in variable 'days': [28, 29, 30, 31]\n",
      "\n",
      "Unique entries in variable 'type': ['Economy', 'Luxury', 'Mid-Tier', 'Upscale']\n"
     ]
    }
   ],
   "source": [
    "#check that the unique values in year, month, days and type are all valid\n",
    "print(\"Unique entries in variable 'year':\", sorted(set(df['year'].dropna()))\n",
    "      + ([np.nan] if df['year'].isnull().sum() > 0 else []))\n",
    "print(\"\\nUnique entries in variable 'month':\", sorted(set(df['month'].dropna()))\n",
    "      + ([np.nan] if df['month'].isnull().sum() > 0 else []))\n",
    "print(\"\\nUnique entries in variable 'days':\", sorted(set(df['days'].dropna()))\n",
    "      + ([np.nan] if df['days'].isnull().sum() > 0 else []))\n",
    "print(\"\\nUnique entries in variable 'type':\", sorted(set(df['type'].dropna()))\n",
    "      + ([np.nan] if df['type'].isnull().sum() > 0 else []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Dependent Y-Variable as 'room_receipt' and dropping 'room_rate' due to the 'room_receipt ~ room_rate * occupancy_rate' relationship\n",
    "In this assignment, the dependent Y-variable to be predicted is ‘room receipt’. \n",
    "\n",
    "When I previously run the code for interactions and came up with a least squares regression for all variables including the interactions, I discovered that occupancy_rate x room_rate has very high t-value and a P-value of close to 0. This is interesting, and upon closer inspection of the excel data, it appears likely that the room receipt column of the excel data can be very closely approximated by taking the occupancy rate x room rate. Logically, this relationship is also not only reasonable, but also justified. \n",
    "\n",
    "As such I have decided to drop 'occupancy_rate' in my analysis. This would allow my model to be trained to predict values for 'room_receipt' without knowledge of the 'occupancy_rate'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_receipt', 'year', 'month', 'days', 'type', 'room_rate']\n"
     ]
    }
   ],
   "source": [
    "y = 'room_receipt'\n",
    "#drop 'room_rate' from the dataframe\n",
    "df.drop('occupancy_rate', axis=1, inplace=True)\n",
    "#get column names:\n",
    "colname = list(df)\n",
    "#move y to position 0:\n",
    "colname.insert(0, colname.pop(colname.index(y)))\n",
    "df = df[colname]\n",
    "print(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "Create categorical variables for 'type', 'year', 'days' and 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in text variable 'type': ['Economy', 'Luxury', 'Mid-Tier', 'Upscale']\n",
      "\n",
      "Categorical dummies from text variable 'type':\n",
      "\n",
      "   t_Luxury  t_Midtier  t_Upscale\n",
      "0         1          0          0\n",
      "1         1          0          0\n",
      "2         1          0          0\n",
      "\n",
      "Unique values in numeric variable 'month': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "\n",
      "Categorical dummies from numeric variable 'month':\n",
      "\n",
      "   m_2  m_3  m_4  m_5  m_6  m_7  m_8  m_9  m_10  m_11  m_12\n",
      "0    0    0    0    0    0    0    0    0     0     0     0\n",
      "1    0    0    0    0    0    0    0    0     0     0     1\n",
      "2    0    0    0    0    0    0    0    0     0     1     0\n",
      "\n",
      "Unique values in numeric variable 'year': [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "\n",
      "Categorical dummies from numeric variable 'year:\n",
      "\n",
      "   y_2009  y_2010  y_2011  y_2012  y_2013  y_2014  y_2015  y_2016  y_2017  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   y_2018  y_2019  y_2020  \n",
      "0       0       0       1  \n",
      "1       0       1       0  \n",
      "2       0       1       0  \n",
      "Unique values in numeric variable 'days': [28, 29, 30, 31]\n",
      "\n",
      "Categorical dummies from numeric variable 'days':\n",
      "\n",
      "   d_29  d_30  d_31\n",
      "0     0     0     1\n",
      "1     0     0     1\n",
      "2     0     1     0\n"
     ]
    }
   ],
   "source": [
    "#turn text variable Type into categorical dummies\n",
    "print(\"\\nUnique values in text variable 'type':\", sorted(set(df['type'].dropna()))\n",
    "      + ([np.nan] if df['type'].isnull().sum() > 0 else []))\n",
    "\n",
    "#use short prefix 't' instead of the obvious 'type' for better printing output\n",
    "d1 = pd.get_dummies(df['type'], prefix='t', drop_first=True)\n",
    "d1.rename(columns={'t_Mid-Tier': 't_Midtier'},inplace=True)\n",
    "print(\"\\nCategorical dummies from text variable 'type':\\n\")\n",
    "print(d1.head(3))\n",
    "\n",
    "#turn numeric variable month into categorical dummies\n",
    "print(\"\\nUnique values in numeric variable 'month':\", sorted(set(df['month'].dropna()))\n",
    "      + ([np.nan] if df['month'].isnull().sum() > 0 else []))\n",
    "\n",
    "#use short prefix 'm' instead of the obvious 'month' for better printing output\n",
    "d2 = pd.get_dummies(df['month'], prefix='m', drop_first=True)\n",
    "\n",
    "print(\"\\nCategorical dummies from numeric variable 'month':\\n\")\n",
    "print(d2.head(3))\n",
    "\n",
    "#turn numeric variable Year into categorical dummies\n",
    "print(\"\\nUnique values in numeric variable 'year':\", sorted(set(df['year'].dropna()))\n",
    "      + ([np.nan] if df['year'].isnull().sum() > 0 else []))\n",
    "\n",
    "#use short prefix 'y' instead of the obvious 'year' for better printing output\n",
    "d3 = pd.get_dummies(df['year'], prefix='y', drop_first=True)\n",
    "\n",
    "print(\"\\nCategorical dummies from numeric variable 'year:\\n\")\n",
    "print(d3.head(3))\n",
    "\n",
    "#turn numeric variable Day into categorical dummies\n",
    "print(\"Unique values in numeric variable 'days':\", sorted(set(df['days'].dropna()))\n",
    "      + ([np.nan] if df['days'].isnull().sum() > 0 else []))\n",
    "\n",
    "#use short prefix 'M' instead of the obvious 'Month' for better printing output\n",
    "d4 = pd.get_dummies(df['days'], prefix='d', drop_first=True)\n",
    "\n",
    "print(\"\\nCategorical dummies from numeric variable 'days':\\n\")\n",
    "print(d4.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstituted dataset has 577 rows.\n",
      "\n",
      "['room_receipt', 'room_rate', 't_Luxury', 't_Midtier', 't_Upscale', 'm_2', 'm_3', 'm_4', 'm_5', 'm_6', 'm_7', 'm_8', 'm_9', 'm_10', 'm_11', 'm_12', 'y_2009', 'y_2010', 'y_2011', 'y_2012', 'y_2013', 'y_2014', 'y_2015', 'y_2016', 'y_2017', 'y_2018', 'y_2019', 'y_2020', 'd_29', 'd_30', 'd_31']\n"
     ]
    }
   ],
   "source": [
    "#reconstitute dataframe df:\n",
    "df = pd.concat([df.drop(['type', 'month', 'year', 'days'], axis=1), d1, d2, d3, d4], axis=1)\n",
    "print('Reconstituted dataset has', len(df), 'rows.\\n')\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Transformation\n",
    "- square and square-root when variable non-negative\n",
    "- cube and cube-root for variable with any negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   room_receipt   room_rate  room_rate_sqar  room_rate_sqrt\n",
      "0    422.755465  506.427381   256468.692180       22.503941\n",
      "1    426.837353  493.608149   243649.004977       22.217294\n",
      "2    406.007682  452.747203   204980.029373       21.277857 \n",
      "\n",
      "Reconstituted dataset has 577 rows.\n",
      "\n",
      "['room_receipt', 'room_rate', 't_Luxury', 't_Midtier', 't_Upscale', 'm_2', 'm_3', 'm_4', 'm_5', 'm_6', 'm_7', 'm_8', 'm_9', 'm_10', 'm_11', 'm_12', 'y_2009', 'y_2010', 'y_2011', 'y_2012', 'y_2013', 'y_2014', 'y_2015', 'y_2016', 'y_2017', 'y_2018', 'y_2019', 'y_2020', 'd_29', 'd_30', 'd_31', 'room_rate_sqar', 'room_rate_sqrt']\n"
     ]
    }
   ],
   "source": [
    "#use only a subset of Xs:\n",
    "df_trans = df[['room_receipt','room_rate']].copy()\n",
    "\n",
    "#add squares and sqrt of Xs:\n",
    "for i in list(df_trans)[1:]: \n",
    "    if sum(df_trans[i] < 0) == 0: \n",
    "        df_trans[i + '_sqar'] = df[i] ** 2 \n",
    "        df_trans[i + '_sqrt'] = np.sqrt(df[i]) \n",
    "    else: \n",
    "        df_trans[i + '_cube'] = df[i] ** 3\n",
    "        df_trans[i + '_cbrt'] = np.cbrt(df[i])\n",
    "\n",
    "#verify square & square-root: \n",
    "print(df_trans.head(3), '\\n')\n",
    "\n",
    "#concatenate transformed variables to the original dataframe df:\n",
    "df = df.join(df_trans.drop(['room_rate'], axis=1).set_index('room_receipt'), on='room_receipt')\n",
    "print('Reconstituted dataset has', len(df), 'rows.\\n')\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for collinearity of one raw variable with another raw variable\n",
    "Delete any raw x too highly correlated with another raw x, to avoid collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X pairs with correlations > 0.995 :\n",
      "(no more)\n",
      "\n",
      "0 collinear variables deleted.\n"
     ]
    }
   ],
   "source": [
    "corv = pd.DataFrame() #start empty dataframe for corr(Xs, y) to come\n",
    "for x in list(df)[1:]:\n",
    "    #during 1st time thru loop, new column, with label, created in empty dataframe\n",
    "    corv.loc[x, y] = df[x].corr(df[y]) #new entry, with row label, added to dataframe\n",
    "\n",
    "corv = corv.loc[abs(corv).sort_values([y]).index, :] #corr(Xs, y) ranked\n",
    "\n",
    "delta = 0.005 #corr difference lower limit\n",
    "dl2 = []\n",
    "icorr = True\n",
    "while icorr:\n",
    "    a = abs(corv).diff() <= delta #adjacent rows with similar abs(corr(Xs, y))\n",
    "    colname = list(df)[1:]\n",
    "    dl = []\n",
    "    print('\\nX pairs with correlations >', 1 - delta, ':')\n",
    "    for b in range(1, a.shape[0]):\n",
    "        if a.iloc[b, 0]:\n",
    "            if abs(df[a.index[b - 1]].corr(df[a.index[b]])) > 1 - delta:\n",
    "                #deleting 1 X from correlated pair:\n",
    "                dv0 = a.index[b - 1]\n",
    "                dv1 = a.index[b]\n",
    "\n",
    "                #neither should already be deleted:\n",
    "                if not (dv0 in dl) and not (dv1 in dl):\n",
    "                    #delete x with rather lower corr(x, y):\n",
    "                    if abs(corv.loc[dv0, y]) - abs(corv.loc[dv1, y]) >= delta:\n",
    "                        d = dv1\n",
    "                    elif len(dv0) < len(dv1): #delete x with longer name:\n",
    "                        d = dv1\n",
    "                    else:\n",
    "                        d = dv0\n",
    "\n",
    "                    dl.append(d) #for en masse deletion later\n",
    "                    corv.drop([d], axis=0, inplace=True) #delete from column of corr with y\n",
    "\n",
    "                    print(dv0,',',dv1)\n",
    "\n",
    "    if len(dl) > 0:\n",
    "        df.drop(axis=1, columns=dl, inplace=True) #variables deleted en masse\n",
    "        dl2 = dl2 + dl #keep for real deletion later\n",
    "        print('\\n' + str(len(dl)), 'variables considered for deletion:')\n",
    "        print('\\n'.join([str(x) for x in dl]))\n",
    "    else:\n",
    "        print('(no more)')\n",
    "        icorr = False\n",
    "\n",
    "#remaining Xs may be collinear\n",
    "print('\\n' + str(len(dl2)), 'collinear variables deleted.')\n",
    "\n",
    "#potential collinearity issues handled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Perform feature selection using adjusted R2 after transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_receipt ~ room_rate + t_Luxury + t_Midtier + t_Upscale + m_2 + m_3 + m_4 + m_5 + m_6 + m_7 + m_8 + m_9 + m_10 + m_11 + m_12 + y_2009 + y_2010 + y_2011 + y_2012 + y_2013 + y_2014 + y_2015 + y_2016 + y_2017 + y_2018 + y_2019 + y_2020 + d_29 + d_30 + d_31 + room_rate_sqar + room_rate_sqrt\n",
      "\n",
      "Adjusted R2 = 0.9919817317717686   &   max(p-value) = 0.942336892579906   for 32 Xs.\n",
      "Variable to drop: m_5\n",
      "\n",
      "Adjusted R2 = 0.9919963136319011   &   max(p-value) = 0.8055702304365819   for 31 Xs.\n",
      "Variable to drop: y_2020\n",
      "\n",
      "Adjusted R2 = 0.9920100331483246   &   max(p-value) = 0.69695528703099   for 30 Xs.\n",
      "Variable to drop: d_29\n",
      "\n",
      "Adjusted R2 = 0.992022377310482   &   max(p-value) = 0.6924031397432802   for 29 Xs.\n",
      "Variable to drop: t_Midtier\n",
      "\n",
      "Adjusted R2 = 0.9920346097463375   &   max(p-value) = 0.3911715873689622   for 28 Xs.\n",
      "Variable to drop: m_9\n",
      "\n",
      "Adjusted R2 = 0.9920346097463375   &   max(p-value) = 0.09814946315094766   for 27 Xs.\n",
      "Variable to drop: y_2009\n",
      "\n",
      "Adjusted R2 = 0.9920093883552589   &   max(p-value) = 0.10958846414632932   for 26 Xs.\n",
      "Variable to drop: room_rate_sqar\n",
      "\n",
      "Adjusted R2 = 0.9919866840594926   &   max(p-value) = 0.6173023881633415   for 25 Xs.\n",
      "Variable to drop: d_30\n",
      "\n",
      "Adjusted R2 = 0.9919866840594926   &   max(p-value) = 0.016180869498583262   for 24 Xs.\n",
      "Variable to drop: d_31\n",
      "\n",
      "Adjusted R2 = 0.9919168565892357   &   max(p-value) = 0.04045703303244929   for 23 Xs.\n",
      "Variable to drop: m_12\n",
      "\n",
      "Adjusted R2 = 0.9918698982284321   &   max(p-value) = 0.0003652595341908233   for 22 Xs.\n",
      "Variable to drop: m_4\n",
      "\n",
      "Adjusted R2 = 0.9916961561437543   &   max(p-value) = 6.352291973474529e-05   for 21 Xs.\n",
      "Variable to drop: y_2012\n",
      "\n",
      "Adjusted R2 = 0.9914685154906929   &   max(p-value) = 1.924756530616482e-05   for 20 Xs.\n",
      "Variable to drop: y_2011\n",
      "\n",
      "Adjusted R2 = 0.991199207027813   &   max(p-value) = 0.0003662818815220613   for 19 Xs.\n",
      "Variable to drop: y_2016\n",
      "\n",
      "Adjusted R2 = 0.991012241267399   &   max(p-value) = 0.00024770198004737905   for 18 Xs.\n",
      "Variable to drop: y_2015\n",
      "\n",
      "Adjusted R2 = 0.9908095795721725   &   max(p-value) = 0.00045466753416145076   for 17 Xs.\n",
      "Variable to drop: y_2014\n",
      "\n",
      "Adjusted R2 = 0.9906218265282066   &   max(p-value) = 0.0008330058451394741   for 16 Xs.\n",
      "Variable to drop: y_2017\n",
      "\n",
      "Adjusted R2 = 0.990449835874989   &   max(p-value) = 0.002460967536410847   for 15 Xs.\n",
      "Variable to drop: y_2010\n",
      "\n",
      "Adjusted R2 = 0.9903095906327639   &   max(p-value) = 0.0003613234739902611   for 14 Xs.\n",
      "Variable to drop: y_2013\n",
      "\n",
      "Adjusted R2 = 0.9901051291494011   &   max(p-value) = 4.4869052440101313e-05   for 13 Xs.\n",
      "Variable to drop: y_2018\n",
      "\n",
      "Adjusted R2 = 0.989825873007662   &   max(p-value) = 3.1610523245285727e-05   for 12 Xs.\n",
      "Variable to drop: m_6\n",
      "\n",
      "Adjusted R2 = 0.9895269000652614   &   max(p-value) = 0.00014771250431673628   for 11 Xs.\n",
      "Variable to drop: m_2\n",
      "\n",
      "Adjusted R2 = 0.989275262579648   &   max(p-value) = 0.0005895087995071404   for 10 Xs.\n",
      "Variable to drop: m_10\n",
      "\n",
      "Adjusted R2 = 0.9890682675145717   &   max(p-value) = 0.00021790956406980946   for 9 Xs.\n",
      "Variable to drop: m_11\n",
      "\n",
      "Adjusted R2 = 0.988820986435028   &   max(p-value) = 0.00012942211958078605   for 8 Xs.\n",
      "Variable to drop: m_3\n",
      "\n",
      "Adjusted R2 = 0.9885488008161615   &   max(p-value) = 6.722046772188235e-06   for 7 Xs.\n",
      "Variable to drop: y_2019\n",
      "\n",
      "Adjusted R2 = 0.9881539441371879   &   max(p-value) = 1.5618867594097153e-08   for 6 Xs.\n",
      "Variable to drop: m_8\n",
      "\n",
      "Adjusted R2 = 0.9874917653920853   &   max(p-value) = 6.127031479367295e-10   for 5 Xs.\n",
      "Variable to drop: room_rate_sqrt\n",
      "\n",
      "Adjusted R2 = 0.9866470536729004   &   max(p-value) = 5.605740416526318e-11   for 4 Xs.\n",
      "Variable to drop: m_7\n",
      "\n",
      "Adjusted R2 = 0.9856299084689979   &   max(p-value) = 2.312300689965468e-15   for 3 Xs.\n",
      "Variable to drop: t_Upscale\n",
      "\n",
      "Adjusted R2 = 0.9839924188390105   &   max(p-value) = 7.937323634036955e-20   for 2 Xs.\n",
      "Variable to drop: t_Luxury\n",
      "\n",
      "Adjusted R2 = 0.9815297737485665   &   max(p-value) = 0.0   for 1 Xs.\n",
      "Variable left: room_rate\n",
      "\n",
      "Best model has 24 Xs:\n",
      "                 Results: Ordinary least squares\n",
      "==================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.992    \n",
      "Dependent Variable: room_receipt     AIC:                4252.4968\n",
      "Date:               2021-02-17 01:39 BIC:                4361.4428\n",
      "No. Observations:   577              Log-Likelihood:     -2101.2  \n",
      "Df Model:           24               F-statistic:        2972.    \n",
      "Df Residuals:       552              Prob (F-statistic): 0.00     \n",
      "R-squared:          0.992            Scale:              89.101   \n",
      "------------------------------------------------------------------\n",
      "                Coef.   Std.Err.    t     P>|t|   [0.025   0.975] \n",
      "------------------------------------------------------------------\n",
      "Intercept       19.5761   8.8752   2.2057 0.0278   2.1428  37.0095\n",
      "room_rate        1.3001   0.0461  28.2135 0.0000   1.2096   1.3906\n",
      "t_Luxury       -54.6774   3.6716 -14.8920 0.0000 -61.8894 -47.4654\n",
      "t_Upscale      -13.1662   1.7066  -7.7148 0.0000 -16.5185  -9.8140\n",
      "m_2             10.6372   1.9397   5.4840 0.0000   6.8271  14.4472\n",
      "m_3              8.8022   1.6661   5.2831 0.0000   5.5295  12.0749\n",
      "m_4              7.5010   1.9554   3.8360 0.0001   3.6600  11.3420\n",
      "m_6              9.8559   1.9628   5.0212 0.0000   6.0004  13.7115\n",
      "m_7             16.5046   1.6665   9.9035 0.0000  13.2310  19.7781\n",
      "m_8             12.9271   1.6660   7.7595 0.0000   9.6547  16.1996\n",
      "m_10             6.7361   1.6664   4.0423 0.0001   3.4629  10.0094\n",
      "m_11            12.0226   1.9502   6.1648 0.0000   8.1919  15.8533\n",
      "m_12            -4.5967   1.6693  -2.7537 0.0061  -7.8756  -1.3178\n",
      "y_2010          11.9082   1.6675   7.1414 0.0000   8.6328  15.1835\n",
      "y_2011           9.3665   1.6954   5.5247 0.0000   6.0363  12.6966\n",
      "y_2012           6.8154   1.7567   3.8797 0.0001   3.3648  10.2660\n",
      "y_2013          14.0315   1.7110   8.2007 0.0000  10.6706  17.3924\n",
      "y_2014          12.0947   1.7308   6.9880 0.0000   8.6950  15.4945\n",
      "y_2015          11.2106   1.7112   6.5512 0.0000   7.8493  14.5718\n",
      "y_2016           9.8786   1.7080   5.7839 0.0000   6.5237  13.2335\n",
      "y_2017          12.4182   1.7016   7.2979 0.0000   9.0758  15.7606\n",
      "y_2018          15.4650   1.7094   9.0473 0.0000  12.1073  18.8226\n",
      "y_2019          17.2940   1.7195  10.0573 0.0000  13.9163  20.6716\n",
      "d_31             4.0986   1.6991   2.4122 0.0162   0.7611   7.4361\n",
      "room_rate_sqrt  -8.8651   1.2675  -6.9943 0.0000 -11.3548  -6.3755\n",
      "------------------------------------------------------------------\n",
      "Omnibus:              224.182      Durbin-Watson:         1.162   \n",
      "Prob(Omnibus):        0.000        Jarque-Bera (JB):      2630.458\n",
      "Skew:                 -1.370       Prob(JB):              0.000   \n",
      "Kurtosis:             13.095       Condition No.:         6254    \n",
      "==================================================================\n",
      "* The condition number is large (6e+03). This might indicate\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "X-coefficients' |t-stats| ranked:\n",
      "\n",
      "                    Coefficient     t-stat          P>|t|\n",
      "1        room_rate     1.300124  28.213505  4.219198e-109\n",
      "2         t_Luxury   -54.677413 -14.891951   2.081955e-42\n",
      "3           y_2019    17.293964  10.057292   5.799623e-22\n",
      "4              m_7    16.504561   9.903459   2.156698e-21\n",
      "5           y_2018    15.464987   9.047257   2.491657e-18\n",
      "6           y_2013    14.031477   8.200721   1.684438e-15\n",
      "7              m_8    12.927132   7.759479   4.151879e-14\n",
      "8        t_Upscale   -13.166209  -7.714827   5.698860e-14\n",
      "9           y_2017    12.418205   7.297891   1.023591e-12\n",
      "10          y_2010    11.908166   7.141448   2.928139e-12\n",
      "11  room_rate_sqrt    -8.865113  -6.994315   7.739261e-12\n",
      "12          y_2014    12.094734   6.987970   8.067606e-12\n",
      "13          y_2015    11.210554   6.551242   1.309151e-10\n",
      "14            m_11    12.022634   6.164850   1.362993e-09\n",
      "15          y_2016     9.878614   5.783901   1.223169e-08\n",
      "16          y_2011     9.366454   5.524738   5.090653e-08\n",
      "17             m_2    10.637154   5.484027   6.337145e-08\n",
      "18             m_3     8.802218   5.283059   1.831309e-07\n",
      "19             m_6     9.855919   5.021235   6.940015e-07\n",
      "20            m_10     6.736126   4.042344   6.044015e-05\n",
      "21          y_2012     6.815389   3.879660   1.172261e-04\n",
      "22             m_4     7.501019   3.835967   1.395049e-04\n",
      "23            m_12    -4.596684  -2.753705   6.086642e-03\n",
      "24            d_31     4.098582   2.412220   1.618087e-02\n"
     ]
    }
   ],
   "source": [
    "#t-stat p-value kept below .05\n",
    "df0 = df.copy()\n",
    "df3 = df.copy()\n",
    "modeleq = ' + '.join(list(df3)).replace('+', '~', 1)\n",
    "print(modeleq)\n",
    "maxR2 = -np.inf\n",
    "bmodeleq = modeleq\n",
    "R205 = -np.inf\n",
    "modeleq05 = ''\n",
    "numx = df3.shape[1] - 1\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "while True:\n",
    "    regout = ols(modeleq, df3).fit()\n",
    "    R2 = regout.rsquared_adj\n",
    "    maxp = max(regout.pvalues[1:])\n",
    "    #see if a better model is found:\n",
    "    if R2 > maxR2:\n",
    "        maxR2 = R2\n",
    "        bmodeleq = modeleq\n",
    "        if maxp >= 0.05:\n",
    "            #reset p-value criterion:\n",
    "            R205 = -np.inf\n",
    "            modeleq05 = ''\n",
    "    \n",
    "    #see if a better model is found with max(t-stat p-value) < .05:\n",
    "    if maxp < .05 and R2 > R205:\n",
    "        R205 = R2\n",
    "        modeleq05 = modeleq\n",
    "        \n",
    "    print('\\nAdjusted R2 =', R2, '  &   max(p-value) =', maxp, '  for', numx, 'Xs.')\n",
    "\n",
    "    if numx == 1:\n",
    "        print('Variable left:', modeleq[modeleq.find('~') + 2 :])\n",
    "        # 1 xvar left\n",
    "        break\n",
    "\n",
    "    #identify X variable to delete by finding the one with smallest abs(t-stat):\n",
    "    t = regout.tvalues[1:]\n",
    "    xdrop = list(t[abs(t) == min(abs(t))].index)[0]\n",
    "    print('Variable to drop:', xdrop)\n",
    "    \n",
    "    df3.drop(xdrop, axis=1, inplace=True)\n",
    "    modeleq = ' + '.join(list(df3)).replace('+', '~', 1)\n",
    "    \n",
    "    numx = numx - 1\n",
    "\n",
    "#see if best model with all t-stat p-values < 0.05 is smaller than best model by adjusted R2:\n",
    "if R205 > -np.inf and len(modeleq05) < len(bmodeleq):\n",
    "    bmodeleq = modeleq05\n",
    "\n",
    "numx = bmodeleq.count('+') + 1\n",
    "print('\\nBest model has', numx, 'Xs:')\n",
    "regout = ols(bmodeleq, df0).fit()\n",
    "print(regout.summary2())\n",
    "\n",
    "if numx > 1:\n",
    "    #construct and print the variables in order of importance:\n",
    "\n",
    "    print(\"\\nX-coefficients' |t-stats| ranked:\\n\")\n",
    "    c = pd.Series(regout.params.index, index=regout.params.index)\n",
    "    df2 = pd.concat([c, regout.params, regout.tvalues, regout.pvalues, abs(regout.tvalues)], axis=1\n",
    "                   ).iloc[1:, :].sort_values(4, ascending=False).iloc[:, :4] #sort by 5th (4) column\n",
    "    df2.columns = ['', 'Coefficient', 't-stat', 'P>|t|']\n",
    "    df2.index = np.arange(1, len(df2) + 1)\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining some dummy variables from 'month', and 'year', and dropping transformed variables for 'room_rate'.\n",
    "- Since the transformed variables for 'room_rate' ranked higher in p-value than the raw, untransformed variable, I decided to drop the transformed one.\n",
    "- To decrease the number of X-variables, I decided to adopt a new model with fewer dummy variables by combining some of them together, testing to see whether the t-stat value for the top ranked variables increases. It did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial variables included before feature selection:\n",
      "['y_2009', 'y_2010', 'y_2011', 'y_2012', 'y_2013', 'y_2014', 'y_2015', 'y_2016', 'y_2017', 'y_2018', 'y_2019', 'y_2020']\n",
      "room_receipt ~ room_rate + t_Luxury + t_Midtier + t_Upscale + m_4 + m_7 + m_10 + m_12 + y_2009 + y_2011 + y_2013 + y_2015 + y_2017 + y_2019 + d_29 + d_30 + d_31\n",
      "\n",
      "Adjusted R2 = 0.9889858079038928   &   max(p-value) = 0.8989330405263941   for 17 Xs.\n",
      "Variable to drop: m_4\n",
      "\n",
      "Adjusted R2 = 0.9890051585407188   &   max(p-value) = 0.6666329435471623   for 16 Xs.\n",
      "Variable to drop: y_2011\n",
      "\n",
      "Adjusted R2 = 0.9890211164944795   &   max(p-value) = 0.49926353803934564   for 15 Xs.\n",
      "Variable to drop: m_10\n",
      "\n",
      "Adjusted R2 = 0.9890317223562871   &   max(p-value) = 0.21363556173223341   for 14 Xs.\n",
      "Variable to drop: y_2015\n",
      "\n",
      "Adjusted R2 = 0.9890210048654166   &   max(p-value) = 0.15684723075784227   for 13 Xs.\n",
      "Variable to drop: d_31\n",
      "\n",
      "Adjusted R2 = 0.9890013493255314   &   max(p-value) = 0.19715708287814038   for 12 Xs.\n",
      "Variable to drop: d_29\n",
      "\n",
      "Adjusted R2 = 0.9889883603334376   &   max(p-value) = 0.0438428626412305   for 11 Xs.\n",
      "Variable to drop: y_2017\n",
      "\n",
      "Adjusted R2 = 0.9889284215111379   &   max(p-value) = 0.015875827053234808   for 10 Xs.\n",
      "Variable to drop: y_2013\n",
      "\n",
      "Adjusted R2 = 0.9888336832709236   &   max(p-value) = 0.00818651639374968   for 9 Xs.\n",
      "Variable to drop: d_30\n",
      "\n",
      "Adjusted R2 = 0.9887149086259104   &   max(p-value) = 0.00014140965312014922   for 8 Xs.\n",
      "Variable to drop: y_2009\n",
      "\n",
      "Adjusted R2 = 0.9884435396275594   &   max(p-value) = 7.868100277571682e-06   for 7 Xs.\n",
      "Variable to drop: y_2019\n",
      "\n",
      "Adjusted R2 = 0.9880513833569119   &   max(p-value) = 2.0708449888336561e-07   for 6 Xs.\n",
      "Variable to drop: m_12\n",
      "\n",
      "Adjusted R2 = 0.9874939505693215   &   max(p-value) = 5.821935398021091e-10   for 5 Xs.\n",
      "Variable to drop: t_Midtier\n",
      "\n",
      "Adjusted R2 = 0.9866470536729004   &   max(p-value) = 5.605740416526318e-11   for 4 Xs.\n",
      "Variable to drop: m_7\n",
      "\n",
      "Adjusted R2 = 0.9856299084689979   &   max(p-value) = 2.312300689965468e-15   for 3 Xs.\n",
      "Variable to drop: t_Upscale\n",
      "\n",
      "Adjusted R2 = 0.9839924188390105   &   max(p-value) = 7.937323634036955e-20   for 2 Xs.\n",
      "Variable to drop: t_Luxury\n",
      "\n",
      "Adjusted R2 = 0.9815297737485665   &   max(p-value) = 0.0   for 1 Xs.\n",
      "Variable left: room_rate\n",
      "\n",
      "Best model has 11 Xs:\n",
      "                 Results: Ordinary least squares\n",
      "==================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.989    \n",
      "Dependent Variable: room_receipt     AIC:                4423.3264\n",
      "Date:               2021-02-17 01:48 BIC:                4475.6205\n",
      "No. Observations:   577              Log-Likelihood:     -2199.7  \n",
      "Df Model:           11               F-statistic:        4704.    \n",
      "Df Residuals:       565              Prob (F-statistic): 0.00     \n",
      "R-squared:          0.989            Scale:              122.44   \n",
      "-------------------------------------------------------------------\n",
      "            Coef.    Std.Err.     t      P>|t|    [0.025    0.975] \n",
      "-------------------------------------------------------------------\n",
      "Intercept  -24.9029    2.3277  -10.6985  0.0000  -29.4748  -20.3309\n",
      "room_rate    1.0447    0.0195   53.4995  0.0000    1.0064    1.0831\n",
      "t_Luxury   -65.0161    6.3812  -10.1886  0.0000  -77.5499  -52.4822\n",
      "t_Midtier   -8.7263    1.9206   -4.5435  0.0000  -12.4987   -4.9539\n",
      "t_Upscale  -25.8897    3.3692   -7.6843  0.0000  -32.5074  -19.2721\n",
      "m_7         10.5315    1.7259    6.1021  0.0000    7.1416   13.9214\n",
      "m_12       -10.1701    1.7271   -5.8885  0.0000  -13.5624   -6.7777\n",
      "y_2009      -6.7538    2.0181   -3.3465  0.0009  -10.7177   -2.7898\n",
      "y_2013       4.4641    1.6957    2.6326  0.0087    1.1335    7.7947\n",
      "y_2017       3.4224    1.6941    2.0201  0.0438    0.0948    6.7499\n",
      "y_2019       8.1925    1.6960    4.8305  0.0000    4.8613   11.5238\n",
      "d_30        -2.7621    1.0358   -2.6665  0.0079   -4.7967   -0.7275\n",
      "------------------------------------------------------------------\n",
      "Omnibus:              215.245      Durbin-Watson:         1.150   \n",
      "Prob(Omnibus):        0.000        Jarque-Bera (JB):      2134.481\n",
      "Skew:                 -1.353       Prob(JB):              0.000   \n",
      "Kurtosis:             12.025       Condition No.:         4488    \n",
      "==================================================================\n",
      "* The condition number is large (4e+03). This might indicate\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "X-coefficients' |t-stats| ranked:\n",
      "\n",
      "               Coefficient     t-stat          P>|t|\n",
      "1   room_rate     1.044728  53.499454  2.501998e-223\n",
      "2    t_Luxury   -65.016057 -10.188633   1.706729e-22\n",
      "3   t_Upscale   -25.889727  -7.684252   6.844521e-14\n",
      "4         m_7    10.531470   6.102097   1.944774e-09\n",
      "5        m_12   -10.170057  -5.888508   6.691337e-09\n",
      "6      y_2019     8.192508   4.830458   1.756760e-06\n",
      "7   t_Midtier    -8.726282  -4.543508   6.769119e-06\n",
      "8      y_2009    -6.753751  -3.346526   8.726870e-04\n",
      "9        d_30    -2.762106  -2.666541   7.883150e-03\n",
      "10     y_2013     4.464083   2.632614   8.704822e-03\n",
      "11     y_2017     3.422360   2.020115   4.384286e-02\n"
     ]
    }
   ],
   "source": [
    "#perform feature selection using adjusted R2 after transformation\n",
    "#t-stat p-value kept below .05\n",
    "df3 = df.drop(['room_rate_sqrt', 'room_rate_sqar', 'y_2020', 'y_2018', 'y_2016', 'y_2014',\n",
    "               'y_2012', 'y_2010', 'm_2',  'm_3',  'm_5',  'm_6',  'm_8',  'm_9', 'm_11'], axis=1)\n",
    "\n",
    "print('Initial variables included before feature selection:')\n",
    "print(list(d3))\n",
    "modeleq = ' + '.join(list(df3)).replace('+', '~', 1)\n",
    "print(modeleq)\n",
    "maxR2 = -np.inf\n",
    "bmodeleq = modeleq\n",
    "R205 = -np.inf\n",
    "modeleq05 = ''\n",
    "numx = df3.shape[1] - 1\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "while True:\n",
    "    regout = ols(modeleq, df3).fit()\n",
    "    R2 = regout.rsquared_adj\n",
    "    maxp = max(regout.pvalues[1:])\n",
    "    #see if a better model is found:\n",
    "    if R2 > maxR2:\n",
    "        maxR2 = R2\n",
    "        bmodeleq = modeleq\n",
    "        if maxp >= 0.05:\n",
    "            #reset p-value criterion:\n",
    "            R205 = -np.inf\n",
    "            modeleq05 = ''\n",
    "    \n",
    "    #see if a better model is found with max(t-stat p-value) < .05:\n",
    "    if maxp < .05 and R2 > R205:\n",
    "        R205 = R2\n",
    "        modeleq05 = modeleq\n",
    "        \n",
    "    print('\\nAdjusted R2 =', R2, '  &   max(p-value) =', maxp, '  for', numx, 'Xs.')\n",
    "\n",
    "    if numx == 1:\n",
    "        print('Variable left:', modeleq[modeleq.find('~') + 2 :])\n",
    "        # 1 xvar left\n",
    "        break\n",
    "\n",
    "    #identify X variable to delete by finding the one with smallest abs(t-stat):\n",
    "    t = regout.tvalues[1:]\n",
    "    xdrop = list(t[abs(t) == min(abs(t))].index)[0]\n",
    "    print('Variable to drop:', xdrop)\n",
    "    \n",
    "    df3.drop(xdrop, axis=1, inplace=True)\n",
    "    modeleq = ' + '.join(list(df3)).replace('+', '~', 1)\n",
    "    \n",
    "    numx = numx - 1\n",
    "\n",
    "#see if best model with all t-stat p-values < 0.05 is smaller than best model by adjusted R2:\n",
    "if R205 > -np.inf and len(modeleq05) < len(bmodeleq):\n",
    "    bmodeleq = modeleq05\n",
    "\n",
    "numx = bmodeleq.count('+') + 1\n",
    "print('\\nBest model has', numx, 'Xs:')\n",
    "regout = ols(bmodeleq, df0).fit()\n",
    "print(regout.summary2())\n",
    "\n",
    "if numx > 1:\n",
    "    #construct and print the variables in order of importance:\n",
    "\n",
    "    print(\"\\nX-coefficients' |t-stats| ranked:\\n\")\n",
    "    c = pd.Series(regout.params.index, index=regout.params.index)\n",
    "    df2 = pd.concat([c, regout.params, regout.tvalues, regout.pvalues, abs(regout.tvalues)], axis=1\n",
    "                   ).iloc[1:, :].sort_values(4, ascending=False).iloc[:, :4] #sort by 5th (4) column\n",
    "    df2.columns = ['', 'Coefficient', 't-stat', 'P>|t|']\n",
    "    df2.index = np.arange(1, len(df2) + 1)\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind that using too many independent variables may make it difficult to explain the significance of specific variables in the model, I decided use the top 9 variables with the highest t-stats values for the final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_rate', 't_Luxury', 't_Upscale', 'm_7', 'm_12', 'y_2019', 't_Midtier', 'y_2009', 'd_30']\n"
     ]
    }
   ],
   "source": [
    "df5 = df2[''][:-2] #list of all the Xs that will be used to train the model\n",
    "print(list(df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training (3/4) and testing (1/4) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_rate', 't_Luxury', 't_Upscale', 'm_7', 'm_12', 'y_2019', 't_Midtier', 'y_2009', 'd_30']\n"
     ]
    }
   ],
   "source": [
    "print(list(df5))\n",
    "y = df.loc[:, 'room_receipt'].values\n",
    "X = df.loc[:, list(df5)].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import metrics\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "#splitting data into test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and predicting based on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(Xtr, ytr)\n",
    "#fitting model with training data\n",
    "predictions = model.predict(Xte)\n",
    "#predicting with model and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.scatter(y=predictions, x=yte)\n",
    "pl.title('Predicted vs actual room room receipt')\n",
    "pl.ylabel('Predicted room receipt')\n",
    "pl.xlabel('Actual room receipt')\n",
    "\n",
    "lineStart = 0\n",
    "lineEnd = 600\n",
    "pl.plot([lineStart, lineEnd], [lineStart, lineEnd], 'k-', color = 'g', label='y=x')\n",
    "pl.xlim(lineStart, lineEnd)\n",
    "pl.ylim(lineStart, lineEnd)\n",
    "pl.axis('square')\n",
    "pl.grid()\n",
    "pl.legend(loc='upper left')\n",
    "pl.rcParams[\"figure.figsize\"] = [6.000, 6.145] # for square plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the coefficients corresponding to each variable included in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " 1 room_rate   1.015218\n",
      "2  t_Luxury -55.919560\n",
      "3 t_Upscale -22.061815\n",
      "4       m_7  10.718694\n",
      "5      m_12  -8.132801\n",
      "6    y_2019   7.237425\n",
      "7 t_Midtier  -6.354859\n",
      "8    y_2009  -8.301015\n",
      "9      d_30  -2.553163\n"
     ]
    }
   ],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(df5.reset_index()),pd.DataFrame(np.transpose(model.coef_))], axis = 1)\n",
    "#concatenate the columns from panda dataframe with coefficients from model\n",
    "print('Coefficients: \\n', coefficients.to_string(index=False, header=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing R^2, RMSE and MAE values for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error: 11.349760060133516\n",
      "R^2: 0.9892032183767624\n",
      "MAE: 5.539340945318372\n"
     ]
    }
   ],
   "source": [
    "print('\\nRoot Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yte, predictions)))\n",
    "print('R^2:', metrics.r2_score(yte, predictions))\n",
    "print('MAE:', metrics.median_absolute_error(yte, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report on Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the R^2 value of 0.989 means that 98.9% percent of the dependent variable variation can be explained by the model; whether this is satisfactory depends on the client's target accuracy for the predictive model.\n",
    " \n",
    "However, considering that RMSE has the same unit as the dependent variable ‘room_receipt’ (which varies from 52 to 454), the RMSE of 11.35 for the model is high. Furthermore, while the MAE is weights all the errors equally, the RMSE gives a higher weight to larger errors. Thus, comparing the RMSE value with the MAE value of 5.54, we see that the regression does not account for some relatively large errors, and could be improved in terms of its accuracy. \n",
    "\n",
    "Finally, the number of x-variables in the model could be further reduced to facilitate ease of interpretation and to further increase its explanability. In the current model, room_rate and t_Luxury have the largest absolute t-statistic values (53.50 and 10.19 respectively), suggesting that they are the most \"useful\" variables in predicting room_rate. (162 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
